<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Chat Sample with WebLLM</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        #chat-container {
            border: 1px solid #ccc;
            height: 400px;
            overflow-y: scroll;
            padding: 10px;
            margin-bottom: 10px;
        }
        .message {
            margin-bottom: 10px;
        }
        .user-message {
            text-align: right;
        }
        .ai-message {
            text-align: left;
        }
        #input-container {
            display: flex;
        }
        #user-input {
            flex-grow: 1;
            padding: 10px;
        }
        #send-button {
            padding: 10px 20px;
        }
        .loading {
            color: #999;
        }
        #model-selection-container {
            margin-bottom: 10px;
        }
        #model-selection {
            padding: 5px;
            margin-right: 10px;
        }
        #load-model-button {
            padding: 5px 10px;
        }
        #loading-message {
            margin-bottom: 10px;
        }
    </style>
</head>
<body>
    <h1>AI Chat Sample with WebLLM</h1>
    <div id="model-selection-container">
        <label for="model-selection">选择模型:</label>
        <select id="model-selection">
            <optgroup label="Llama-3.2 (1B) - 轻量级">
                <option value="Llama-3.2-1B-Instruct-q4f16_1-MLC">Llama-3.2-1B q4f16_1 (879MB VRAM)</option>
                <option value="Llama-3.2-1B-Instruct-q4f32_1-MLC">Llama-3.2-1B q4f32_1 (1.1GB VRAM)</option>
            </optgroup>
            <optgroup label="Llama-3.2 (3B) - 平衡型">
                <option value="Llama-3.2-3B-Instruct-q4f16_1-MLC">Llama-3.2-3B q4f16_1 (2.3GB VRAM)</option>
                <option value="Llama-3.2-3B-Instruct-q4f32_1-MLC">Llama-3.2-3B q4f32_1 (3GB VRAM)</option>
            </optgroup>
            <optgroup label="Llama-3.1 (8B) - 高性能">
                <option value="Llama-3.1-8B-Instruct-q4f16_1-MLC">Llama-3.1-8B q4f16_1 (5GB VRAM)</option>
                <option value="Llama-3.1-8B-Instruct-q4f32_1-MLC">Llama-3.1-8B q4f32_1 (6.1GB VRAM)</option>
                <option value="Llama-3.1-8B-Instruct-q4f16_1-MLC-1k">Llama-3.1-8B q4f16_1-1k (4.6GB VRAM)</option>
                <option value="Llama-3.1-8B-Instruct-q4f32_1-MLC-1k">Llama-3.1-8B q4f32_1-1k (5.3GB VRAM)</option>
            </optgroup>
            <optgroup label="DeepSeek-R1 - 推理专家">
                <option value="DeepSeek-R1-Distill-Qwen-7B-q4f16_1-MLC">DeepSeek-R1-Qwen-7B q4f16_1 (5.1GB VRAM)</option>
                <option value="DeepSeek-R1-Distill-Qwen-7B-q4f32_1-MLC">DeepSeek-R1-Qwen-7B q4f32_1 (5.9GB VRAM)</option>
                <option value="DeepSeek-R1-Distill-Llama-8B-q4f16_1-MLC">DeepSeek-R1-Llama-8B q4f16_1 (5GB VRAM)</option>
                <option value="DeepSeek-R1-Distill-Llama-8B-q4f32_1-MLC">DeepSeek-R1-Llama-8B q4f32_1 (6.1GB VRAM)</option>
            </optgroup>
            <optgroup label="Hermes-3 - 通用助手">
                <option value="Hermes-3-Llama-3.2-3B-q4f16_1-MLC">Hermes-3-Llama-3.2-3B q4f16_1 (2.3GB VRAM)</option>
                <option value="Hermes-3-Llama-3.2-3B-q4f32_1-MLC">Hermes-3-Llama-3.2-3B q4f32_1 (3GB VRAM)</option>
                <option value="Hermes-3-Llama-3.1-8B-q4f16_1-MLC">Hermes-3-Llama-3.1-8B q4f16_1 (4.9GB VRAM)</option>
                <option value="Hermes-3-Llama-3.1-8B-q4f32_1-MLC">Hermes-3-Llama-3.1-8B q4f32_1 (5.8GB VRAM)</option>
            </optgroup>
            <optgroup label="Phi-3.5 - 微软模型">
                <option value="Phi-3.5-mini-instruct-q4f16_1-MLC">Phi-3.5-mini q4f16_1 (3.7GB VRAM)</option>
                <option value="Phi-3.5-mini-instruct-q4f32_1-MLC">Phi-3.5-mini q4f32_1 (5.5GB VRAM)</option>
                <option value="Phi-3.5-mini-instruct-q4f16_1-MLC-1k">Phi-3.5-mini q4f16_1-1k (2.5GB VRAM)</option>
                <option value="Phi-3.5-mini-instruct-q4f32_1-MLC-1k">Phi-3.5-mini q4f32_1-1k (3.2GB VRAM)</option>
            </optgroup>
            <optgroup label="Mistral - 欧洲模型">
                <option value="Hermes-2-Pro-Mistral-7B-q4f16_1-MLC">Hermes-2-Pro-Mistral-7B q4f16_1 (4GB VRAM)</option>
            </optgroup>
            <optgroup label="视觉模型 (VLM)">
                <option value="Phi-3.5-vision-instruct-q4f16_1-MLC">Phi-3.5-vision q4f16_1 (4GB VRAM)</option>
                <option value="Phi-3.5-vision-instruct-q4f32_1-MLC">Phi-3.5-vision q4f32_1 (5.9GB VRAM)</option>
            </optgroup>
        </select>
        <button id="load-model-button">加载模型</button>
    </div>
    <div id="loading-message" class="loading" style="display: none;"></div>
    <div id="chat-container"></div>
    <div id="input-container">
        <input type="text" id="user-input" placeholder="输入消息..." />
        <button id="send-button" disabled>发送</button>
    </div>

    <script type="module" src="app.js"></script>
</body>
</html>